{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 1. FIX: Install Dependencies & Create CORRECT Config"
      ],
      "metadata": {
        "id": "9eqXvJ8Axozh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the correct official CLIP library from source\n",
        "!pip install -q git+https://github.com/openai/CLIP.git\n",
        "# Install core libraries: YOLOv8, Streamlit (UI), pyngrok (Tunneling)\n",
        "# Removing the version pin for ultralytics as suggested by the error message\n",
        "!pip install -q ultralytics supervision streamlit pyngrok\n",
        "!apt-get install ffmpeg -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyMGimB_SiDv",
        "outputId": "e89f9cf0-ea7b-4cce-9aa4-136c8dc41d20"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m128.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streamlit Application Code (app.py)"
      ],
      "metadata": {
        "id": "-IjEF3o3yAEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import cv2\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# --- UI SETUP ---\n",
        "st.set_page_config(page_title=\"YOLOv8 + CLIP Tracker\", layout=\"wide\")\n",
        "st.title(\"ðŸ‘ï¸ AI Object Search & Tracking\")\n",
        "\n",
        "search_threshold = st.sidebar.slider(\"Search Similarity Threshold\", 0.0, 1.0, 0.25, 0.01)\n",
        "confidence_threshold = st.sidebar.slider(\"YOLO Confidence Threshold\", 0.0, 1.0, 0.30, 0.05)\n",
        "search_query = st.sidebar.text_input(\"ðŸ” Search Object (e.g., red car)\")\n",
        "use_clip = st.sidebar.checkbox(\"Enable CLIP Search\")\n",
        "\n",
        "# --- LOAD MODELS (cached) ---\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    yolo = YOLO('yolov8n.pt')  # smaller & faster model\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "    return yolo, clip_model, preprocess, device\n",
        "\n",
        "yolo_model, clip_model, clip_preprocess, device = load_models()\n",
        "\n",
        "# --- UPLOAD ---\n",
        "uploaded_file = st.file_uploader(\"Upload Video (mp4, avi, mov)\", type=['mp4','avi','mov'])\n",
        "\n",
        "if uploaded_file:\n",
        "    # Write to temp file\n",
        "    tmp = tempfile.NamedTemporaryFile(delete=False)\n",
        "    tmp.write(uploaded_file.read())\n",
        "    video_path = tmp.name\n",
        "\n",
        "    # Ensure we only process once per upload\n",
        "    if \"processed\" not in st.session_state:\n",
        "        st.session_state.processed = False\n",
        "\n",
        "    if not st.session_state.processed:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        # Write initial AVI (unencoded) then transcode\n",
        "        avi_path = \"temp_output.avi\"\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "        writer = cv2.VideoWriter(avi_path, fourcc, fps, (width, height))\n",
        "\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        progress = st.progress(0)\n",
        "        status_text = st.empty()\n",
        "\n",
        "        # Precompute CLIP text feature\n",
        "        text_features = None\n",
        "        if use_clip and search_query:\n",
        "            token = clip.tokenize([search_query]).to(device)\n",
        "            with torch.no_grad():\n",
        "                text_features = clip_model.encode_text(token)\n",
        "                text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        frame_index = 0\n",
        "        status_text.text(\"Processing videoâ€¦\")\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # YOLO + track & clip\n",
        "            results = yolo_model.track(frame, conf=confidence_threshold, persist=True, tracker=\"bytetrack.yaml\")\n",
        "            if results and results[0].boxes.id is not None:\n",
        "                boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
        "                for (x1, y1, x2, y2) in boxes:\n",
        "                    is_match = False\n",
        "                    if use_clip and text_features is not None:\n",
        "                        crop = frame[y1:y2, x1:x2]\n",
        "                        if crop.size > 0:\n",
        "                            pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
        "                            inp = clip_preprocess(pil).unsqueeze(0).to(device)\n",
        "                            with torch.no_grad():\n",
        "                                img_feat = clip_model.encode_image(inp)\n",
        "                                img_feat /= img_feat.norm(dim=-1, keepdim=True)\n",
        "                                sim = float(img_feat @ text_features.T)\n",
        "                                is_match = sim >= search_threshold\n",
        "\n",
        "                    if is_match:\n",
        "                        cv2.rectangle(frame, (x1,y1), (x2,y2), (0,0,255), 2)\n",
        "                        cv2.putText(frame, search_query, (x1, y1 - 5),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
        "\n",
        "            writer.write(frame)\n",
        "            frame_index += 1\n",
        "            progress.progress(frame_index / total_frames)\n",
        "            status_text.text(f\"Processingâ€¦ {int((frame_index/total_frames)*100)}%\")\n",
        "\n",
        "        cap.release()\n",
        "        writer.release()\n",
        "\n",
        "        # Transcode to H.264 MP4 so browser can play it\n",
        "        mp4_path = \"processed_output.mp4\"\n",
        "        os.system(f\"ffmpeg -i {avi_path} -vcodec libx264 -preset fast {mp4_path} -y\")\n",
        "\n",
        "        st.session_state.processed = True\n",
        "        status_text.text(\"Processing complete!\")\n",
        "\n",
        "    # --- SHOW RESULT ---\n",
        "    if st.session_state.processed:\n",
        "        st.subheader(\"ðŸŽ‰ Processed Video\")\n",
        "        with open(\"processed_output.mp4\", \"rb\") as f:\n",
        "            video_bytes = f.read()\n",
        "            st.video(video_bytes, format=\"video/mp4\")\n",
        "            st.download_button(\n",
        "                \"ðŸ“¥ Download Processed Video\",\n",
        "                data=video_bytes,\n",
        "                file_name=\"tracked_output.mp4\",\n",
        "                mime=\"video/mp4\"\n",
        "            )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J_IVkZZSiyb",
        "outputId": "f136599a-4d07-4ee2-ed1a-c78bfd92cdf6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3: Launch Streamlit and Ngrok"
      ],
      "metadata": {
        "id": "FtKezPhPyMfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# ðŸ”¥ Start Streamlit\n",
        "print(\"Starting Streamlit...\")\n",
        "streamlit_process = subprocess.Popen(\n",
        "    [\"streamlit\", \"run\", \"app.py\", \"--server.headless\", \"true\"]\n",
        ")\n",
        "\n",
        "# â±ï¸ Give Streamlit time to boot\n",
        "time.sleep(7)\n",
        "\n",
        "# ðŸŒ Set your Ngrok auth token\n",
        "\n",
        "# NGROK_AUTH_TOKEN = input(\"Paste your Ngrok Auth Token: \").strip()\n",
        "# ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "NGROK_AUTH_TOKEN=\"PASTE YOUR NGROK AUTH TOKEN HERE\"\n",
        "\n",
        "# ðŸ”Œ Kill old tunnels & start new one\n",
        "ngrok.kill()\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "\n",
        "print(\"ðŸš€ Streamlit App Live!\")\n",
        "print(public_url)\n",
        "\n",
        "# Keep process alive\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Stopping...\")\n",
        "    ngrok.kill()\n",
        "    streamlit_process.terminate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2vhrFWbSqWR",
        "outputId": "1d91127f-6969-48f0-ac2a-c2a400fb983e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Streamlit...\n",
            "ðŸš€ Streamlit App Live!\n",
            "https://nickeliferous-polypetalous-aryan.ngrok-free.dev\n",
            "Stopping...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt\n"
      ],
      "metadata": {
        "id": "E0DGWoGLS3k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tob9OiCxSydj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}